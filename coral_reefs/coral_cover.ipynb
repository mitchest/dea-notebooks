{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First stab at GBR coral cover\n",
    "\n",
    "## conceptual workflow \n",
    "\n",
    "In the longer run the aim is to sample geo-median imagery and other covariate data (depth, slope, etc) around in situ sample data dates, and then predict time-series coral cover  \n",
    "\n",
    "For the moment, to get the hang of it, use a once-off longer time period mosaic and do categorical maps + coral cover. Something like:  \n",
    "    \n",
    "    1. Generate a once off nice composite, maybe a 2-3 year period (2017-2019? - gives access to Sentinel-2 Level 2?)  \n",
    "    2. Maybe segmentation - **optional to begin with**  \n",
    "    3. Sample from the whole trianing data set (*reef cloud*) [but for the moment sample the same time period and AOI as the mosaic]  \n",
    "    4. Fit a ML model (e.g. RF or SVM etc.)  \n",
    "    5. Explore and validate  \n",
    "    6. experiment with OBIA implementation for relationship/neighbourhood rules  \n",
    "\n",
    "**Cummulaive Q's:**\n",
    "- once settled on a larger area, should I export the temporal composites (and segmentation etc.)?\n",
    "- what are the costs for reprojection? Can you set to use the native/nominal projection of data?\n",
    "- RE the `query` dictionary passed to the loading function or loading helper: does the `output_crs` only apply to output after the processing subsquent to the load, or does it always apply to every time-step found in the collection?  \n",
    "- what happens when you stop execution while dask chunks are processing/queued (seems not to like that...)?  \n",
    "- for lazy eval, is it quicker to `.load()`/`.compute()` just the individual bands, several at one, or the whole lot?  And if several at once, how to do that via the slot method (i.e. `lazy_dat.blue.load()` --> `lazy_day.some_bands.load()`  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Front matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import subprocess as sp\n",
    "import sys\n",
    "import datacube\n",
    "import rasterio\n",
    "\n",
    "import shapely\n",
    "\n",
    "import pydotplus\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from odc.ui import with_ui_cbk\n",
    "from odc.algo import to_f32, xr_geomedian, int_geomedian\n",
    "\n",
    "from io import StringIO\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import Image\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.cog import write_cog\n",
    "\n",
    "sys.path.append(\"../../Scripts\")\n",
    "from dea_datahandling import load_ard\n",
    "from dea_plotting import rgb\n",
    "from dea_dask import create_local_dask_cluster\n",
    "from dea_classificationtools import collect_training_data\n",
    "from dea_classificationtools import predict_xr\n",
    "from dea_plotting import map_shapefile\n",
    "\n",
    "# start the cluster\n",
    "create_local_dask_cluster()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') ## why?\n",
    "\n",
    "dc = datacube.Datacube(app=\"coral_cover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image composite (temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"x\": (151.48837, 152.22467),\n",
    "    \"y\": (-23.17189, -23.60526),\n",
    "    \"time\": (\"2019-06-01\", \"2019-06-05\"),\n",
    "    \"group_by\": \"solar_day\",\n",
    "    \"resolution\": (-10, 10),\n",
    "    'measurements': ['nbar_coastal_aerosol', 'nbar_blue', 'nbar_green', 'nbar_red', 'nbar_nir_1'],\n",
    "    'output_crs': 'EPSG:3577'\n",
    "}\n",
    "\n",
    "s2_collection = load_ard(dc=dc,\n",
    "                         products=[\"s2a_ard_granule\", \"s2b_ard_granule\"],\n",
    "                         dask_chunks={\"time\": 1, \"x\": 2000, \"y\": 2000},\n",
    "                         dtype='native',\n",
    "                         **query)\n",
    "\n",
    "print(s2_collection)\n",
    "\n",
    "s2_geomedian = int_geomedian(s2_collection)\n",
    "# compute - ideally i'd like to be able to load the bands at this point - possible? e.g. s2_geomedian.some_bands.load()\n",
    "s2_geomedian = s2_geomedian.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s2_geomedian)\n",
    "rgb(s2_geomedian, bands = ['nbar_blue', 'nbar_green', 'nbar_red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In situ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral_dat = gpd.read_file(\"gbr_reefcloud_coral.shp\")\n",
    "\n",
    "# fix for the meantime to ensure projections line up\n",
    "#coral_dat = coral_dat.to_crs('EPSG:3577')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(coral_dat))\n",
    "print(coral_dat.head())\n",
    "print(coral_dat.shape[0])\n",
    "class_field = \"class_num\"\n",
    "\n",
    "print(coral_dat.crs)\n",
    "\n",
    "'''\n",
    "# select required cols?\n",
    "coral_dat_lite = gpd.GeoDataFrame(coral_dat[[class_field]])\n",
    "coral_dat_lite['geometry'] = coral_dat.geometry\n",
    "print(coral_dat_lite.head())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just subsample and plot to check\n",
    "coral_dat['random'] = np.random.uniform(0, 1, coral_dat.shape[0])\n",
    "coral_dat_sample = coral_dat[coral_dat.random > 0.999]\n",
    "coral_dat_sample = coral_dat_sample.reset_index(drop=True)\n",
    "\n",
    "#coral_dat_buffs = coral_dat_sample\n",
    "#coral_dat_buffs['geometry'] = coral_dat_sample.geometry.buffer(0.0001)\n",
    "\n",
    "print(coral_dat_sample.shape)\n",
    "#print(coral_dat_buffs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_shapefile(coral_dat_sample, attribute = class_field)\n",
    "#map_shapefile(coral_dat_buffs, attribute = class_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample trianing data\n",
    "\n",
    "- Directly from imagery (rather than from the geomedian generated above), with future in mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_query = {\n",
    "    \"time\": (\"2019-06-01\", \"2019-06-30\"),\n",
    "    \"resolution\": (-10, 10),\n",
    "    'group_by' :'solar_day',\n",
    "    'measurements': ['nbar_coastal_aerosol', 'nbar_blue', 'nbar_green', 'nbar_red', 'nbar_nir_1']\n",
    "}\n",
    "\n",
    "column_names, model_input = collect_training_data(\n",
    "                                    gdf=coral_dat_sample, # use the subset while developing\n",
    "                                    products=[\"s2a_ard_granule\", \"s2b_ard_granule\"],\n",
    "                                    dc_query=samp_query,\n",
    "                                    ncpus=1,\n",
    "                                    custom_func=None,\n",
    "                                    field=class_field,\n",
    "                                    calc_indices=None,\n",
    "                                    reduce_func='median',\n",
    "                                    drop=False,\n",
    "                                    zonal_stats='mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(column_names)\n",
    "print(model_input[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
